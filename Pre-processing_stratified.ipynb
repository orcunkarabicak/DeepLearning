{
 "cells": [
  {
   "cell_type": "code",
   "id": "a2ae33be-f84c-489b-83c4-8c012e7c39fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:15:39.144881Z",
     "start_time": "2024-05-04T12:15:37.737558Z"
    }
   },
   "source": [
    "# Imports and GPU check\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.nn.init as init\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import models\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "# Fix HTTPS certificate error\n",
    "import ssl\n",
    "ssl_create_default_https_context = ssl._create_unverified_context\n",
    "from CustomImageDataset import CustomImageDataset\n",
    "\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "a86f5eba-b4df-498a-b40e-ca58a59856e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:15:39.151502Z",
     "start_time": "2024-05-04T12:15:39.145728Z"
    }
   },
   "source": [
    "def set_seed(seed=42):\n",
    "    \"\"\"Sets the seed for reproducibility.\"\"\"\n",
    "    # Python RNG\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # PyTorch RNGs\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    # Numpy RNG\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # OS RNG\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "def worker_init_fn(worker_id):    \n",
    "    \"\"\"Ensure that the data loading process is deterministic.\"\"\"\n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "    \n",
    "set_seed(42)  "
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "ef6b0c18-5bb1-47bc-a232-398becb44648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:15:39.153704Z",
     "start_time": "2024-05-04T12:15:39.151955Z"
    }
   },
   "source": [
    "base_path = \"/Users/orcunkarabicak/Documents/JADS/Deep Learning/Project/input/IDC_regular_ps50_idx5/\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "bd76eebd-4a9d-410f-a05c-fde0295e810c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:15:39.156755Z",
     "start_time": "2024-05-04T12:15:39.154905Z"
    }
   },
   "source": [
    "folders = [folder for folder in os.listdir(base_path) if not folder.startswith(\".\")]\n",
    "print(len(folders))\n",
    "# 279 patients. MacOS creates a hidden folder .DS_Store breaks the flow."
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "28c9fe6d-d6a0-4543-b105-09e850573672",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:15:50.472461Z",
     "start_time": "2024-05-04T12:15:39.157293Z"
    }
   },
   "source": [
    "total_images = 0\n",
    "for n in range(len(folders)):\n",
    "    patient_id = folders[n]\n",
    "    for c in [0, 1]:\n",
    "        patient_path = base_path + patient_id \n",
    "        class_path = patient_path + \"/\" + str(c) + \"/\"\n",
    "        subfiles = os.listdir(class_path)\n",
    "        total_images += len(subfiles)\n",
    "\n",
    "\n",
    "data = pd.DataFrame(index=np.arange(0, total_images), columns=[\"patient_id\", \"path\", \"target\"])\n",
    "\n",
    "k = 0\n",
    "for n in range(len(folders)):\n",
    "    patient_id = folders[n]\n",
    "    patient_path = base_path + patient_id \n",
    "    for c in [0, 1]:\n",
    "        class_path = patient_path + \"/\" + str(c) + \"/\"\n",
    "        subfiles = os.listdir(class_path)\n",
    "        for m in range(len(subfiles)):\n",
    "            image_path = subfiles[m]\n",
    "            data.loc[k, \"path\"] = class_path + image_path\n",
    "            data.loc[k, \"target\"] = int(c)\n",
    "            data.loc[k, \"patient_id\"] = patient_id\n",
    "            k += 1  \n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:15:50.476447Z",
     "start_time": "2024-05-04T12:15:50.473424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Custom dataset class\n",
    "\n",
    "class BreastCancerDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (Pandas DataFrame): DataFrame containing image paths and labels.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx, 1]  # Access image path\n",
    "        image = Image.open(img_path).convert('RGB')  # Load image and ensure RGB\n",
    "        label = self.dataframe.iloc[idx, 2]  # Access the label\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ],
   "id": "945473c9de2e774",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:15:50.479230Z",
     "start_time": "2024-05-04T12:15:50.476968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_mean_and_variance(loader):\n",
    "    mean = 0.0\n",
    "    variance = 0.0\n",
    "    total_images = 0\n",
    "\n",
    "    for images, _ in loader:\n",
    "        # Rearrange batch to be the shape of [B, C, W * H]\n",
    "        images = images.view(images.size(0), images.size(1), -1)\n",
    "        # Update total_images\n",
    "        total_images += images.size(0)\n",
    "        # Compute mean and variance here\n",
    "        mean += images.mean(2).sum(0) \n",
    "        variance += images.var(2).sum(0)\n",
    "\n",
    "    # Final mean and variance\n",
    "    mean /= total_images\n",
    "    variance /= total_images\n",
    "\n",
    "\n",
    "    return mean, variance"
   ],
   "id": "77ea3fca7429eddd",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Our dataset is imbalanced. We will first split our dataset into train and test preserving the class rations. Afterwards, we will use StratifiedKFold in our train dataset.",
   "id": "1665a9a97a59283d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:15:50.481181Z",
     "start_time": "2024-05-04T12:15:50.479696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Transform and resize the data\n",
    "base_transform = transforms.Compose([\n",
    "    transforms.Resize((50, 50)),  # Resize to 50x50\n",
    "    transforms.ToTensor()  # Convert to tensor\n",
    "])"
   ],
   "id": "0f1706d5-88e2-4599-aa0b-b9643d4dcecd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:15:50.483186Z",
     "start_time": "2024-05-04T12:15:50.481764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "batch_size = 16\n",
    "subset_ratio = 0.03  # Reduced dataset size for quicker training\n",
    "\n",
    "epochs = 20\n",
    "learning_rate = 0.001"
   ],
   "id": "fcc20bb77cad330c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:15:50.593983Z",
     "start_time": "2024-05-04T12:15:50.484831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Data Pre-Processing\n",
    "# Assuming \"target\" is the column containing class labels\n",
    "le = LabelEncoder()\n",
    "data[\"target\"] = le.fit_transform(data[\"target\"])\n",
    "# Create custom datasets for training, validation and testing\n",
    "full_train_df, test_df = train_test_split(data, test_size=0.2, random_state=42, stratify=data[\"target\"])\n",
    "train_df, validation_df = train_test_split(full_train_df, test_size=0.2, random_state=42, stratify=full_train_df[\"target\"])\n",
    "test_dataset = BreastCancerDataset(test_df, transform=base_transform) # Test dataset is being held out to check generalizability of the final model \n",
    "\n",
    "print(f'Train dataset size: {train_df.shape}\\nValidation dataset size: {validation_df.shape}\\nTest dataset size: {test_df.shape}')"
   ],
   "id": "9687c40e21868ae0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: (177615, 3)\n",
      "Validation dataset size: (44404, 3)\n",
      "Test dataset size: (55505, 3)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:15:50.634378Z",
     "start_time": "2024-05-04T12:15:50.594597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Perform train-test split to select a subset while preserving class distribution\n",
    "limited_train_df, _ = train_test_split(full_train_df, train_size=subset_ratio, random_state=42, stratify=full_train_df[\"target\"])\n",
    "\n",
    "limited_train_df, val_df = train_test_split(limited_train_df, test_size=0.2, random_state=42, stratify=limited_train_df[\"target\"])\n",
    "# Check the size of the generated subset\n",
    "print(f'Subset Train dataset size: {limited_train_df.shape}\\nSubset Validation dataset size: {val_df.shape}')\n"
   ],
   "id": "967a304468337486",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset Train dataset size: (5328, 3)\n",
      "Subset Validation dataset size: (1332, 3)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:15:52.393482Z",
     "start_time": "2024-05-04T12:15:50.635125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a custom DataLoader for the training fold\n",
    "train_dataset = BreastCancerDataset(limited_train_df, transform=base_transform)  # Base transform\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, worker_init_fn=worker_init_fn)\n",
    "\n",
    "# Calculate fold-specific mean and standard deviation\n",
    "mean, variance = calculate_mean_and_variance(train_loader)\n",
    "std = np.sqrt(variance)\n",
    "print(f\"Mean: {mean}\")\n",
    "print(f\"Standard Deviation: {std}\")\n",
    "\n",
    "# Update transform with fold-specific mean and standard deviation\n",
    "transform = transforms.Compose([\n",
    "  transforms.Resize((50, 50)),  # Resize to 50x50\n",
    "  transforms.ToTensor(),  # Convert to tensor\n",
    "  transforms.Normalize(mean=mean, std=std)  # Fold-specific normalization\n",
    "])\n",
    "\n",
    "train_dataset = BreastCancerDataset(limited_train_df, transform=transform)  # Updated fold transform\n",
    "val_dataset = BreastCancerDataset(val_df, transform=base_transform) # Using base transform\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, worker_init_fn=worker_init_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, worker_init_fn=worker_init_fn)\n",
    "  \n",
    "print(f\"Full train set size: {len(full_train_df)} - Reduced train set size: {len(train_dataset)} - Validation set size: {len(val_dataset)}\")"
   ],
   "id": "100838aa3a872514",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.8132, 0.6361, 0.7346])\n",
      "Standard Deviation: tensor([0.1016, 0.1556, 0.1165])\n",
      "Full train set size: 222019 - Reduced train set size: 5328 - Validation set size: 1332\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T12:15:52.395301Z",
     "start_time": "2024-05-04T12:15:52.394105Z"
    }
   },
   "cell_type": "code",
   "source": "    ",
   "id": "c380a467ad12ed05",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
